

\bibitem{wavenet} Oord, Aaron van den and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray. WaveNet: A Generative Model for Raw Audio, arXiv (2016).

\bibitem{paralel} Oord, Aaron van den and Li, Yazhe and Babuschkin, Igor and Simonyan, Karen and Vinyals, Oriol and Kavukcuoglu, Koray and Driessche, George van den and Lockhart, Edward and Cobo, Luis C. and Stimberg, Florian and Casagrande, Norman and Grewe, Dominik and Noury, Seb and Dieleman, Sander and Elsen, Erich and Kalchbrenner, Nal and Zen, Heiga and Graves, Alex and King, Helen and Walters, Tom and Belov, Dan and Hassabis, Demis. Parallel WaveNet: Fast High-Fidelity Speech Synthesis, arXiv (2017).

\bibitem{fastspeech} Ren, Yi and Ruan, Yangjun and Tan, Xu and Qin, Tao and Zhao, Sheng and Zhao, Zhou and Liu, Tie-Yan. FastSpeech: Fast, Robust and Controllable Text to Speech, arXiv (2019).

\bibitem{waveglow} Prenger, Ryan and Valle, Rafael and Catanzaro, Bryan. WaveGlow: A Flow-based Generative Network for Speech Synthesis, arXiv (2018).

\bibitem{itu} ITU-T Rec. P.800. Methods for subjective determination of transmission quality (1996). (\textit{p. 18-21})

\bibitem{vtlp}Navdeep Jaitly and E. Hinton. Vocal Tract Length Perturbation (VTLP) improves speech recognition, Proc.of the 2013 IEEE International Conference on Acoustics, Speech, and Signal Processing, (2013). 

\bibitem{xvectors}D. Snyder, D. Garcia-Romero, G. Sell, D. Povey and S. Khudanpur. X-Vectors: Robust DNN Embeddings for Speaker Recognition, IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (2018). 

\bibitem{kaldi}Daniel Povey. Kaldi Speech Recognition Toolkit. Extraído el 12 de septiembre de 2022, https://github.com/kaldi-asr/kaldi. 

\bibitem{melcepstral} R. Kubichek. Mel-cepstral distance measure for objective speech quality assessment, Proc. IEEE Pacific Rim Conference on Communications Computers and Signal Processing (1993). 

\bibitem{pesq}A. W. Rix, J. G. Beerends, M. P. Hollier, and A. P. Hekstra. Perceptual evaluation of speech quality (PESQ) a new method for speech quality assessment of telephone networks and codecs, Proc. ICASSP (2001).

\bibitem{opensrl} Guevara-Rukoz, Adriana and Demirsahin, Isin and He, Fei and Chu, Shan-Hui Cathy and Sarin, Supheakmungkol and Pipatsrisawat, Knot and Gutkin, Alexander and Butryna, Alena and Kjartansson, Oddu. Crowdsourcing Latin American Spanish for Low-Resource Text-to-Speech. Proceedings of The 12th Language Resources and Evaluation Conference (LREC), mayo , Marseille, France (2020) (\textit{p. 6504-6513})

\bibitem{kamil} Kamil, Deja and Ariadna, Sanchez and Julian, Roth and Marius, Cotescu. Automatic Evaluation of Speaker Similarity, arXiv (2022).

\bibitem{vc} Benjamin van Niekerk and Marc-Andre Carbonneau and Julian Zaidi and Matthew Baas and Hugo Seute and Herman Kamper. A Comparison of Discrete and Soft Speech Units for Improved Voice Conversion. International Conference on Acoustics, Speech and Signal Processing (ICASSP) (2022).

\bibitem{SpeakerEmbedding} Shuai Wang and Yanmin Qian and Kai Yu. What Does the Speaker Embedding Encode? Proc. Interspeech 2017. Stockholm, Sweden (2017). (\textit{p. 1497-1501})

\bibitem{hubert} Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman. HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units. arXiv (2021)

\bibitem{griffin} https://paperswithcode.com/method/griffin‐lim‐algorithm

\bibitem{polqa} https://www.itu.int/rec/T-REC-P.863/en

\bibitem{visqol} A. Hines, J. Skoglund, A. C. Kokaram, and N. Harte, “Visqol: an objective speech quality model,” EURASIP Journal on Audio, Speech, and Music Processing, vol. 2015, no. 1, pp. 1–18, 2015.

\bibitem{mosnet} Chen-Chou Lo and Szu-Wei Fu and Wen-Chin Huang and Xin Wang and Junichi Yamagishi and Yu Tsao and Hsin-Min Wang MOSNet: Deep Learning-Based Objective Assessment for Voice Conversion. Interspeech 2019

\bibitem{cdpam} Manocha, Pranay and Jin, Zeyu and Zhang, Richard and Finkelstein, Adam CDPAM: Contrastive learning for perceptual audio similarity. arXiv, 2021.
\bibitem{yoshimura} T. Yoshimura, G. Eje Henter, O. Watts, M. Wester, J. Yamagishi, and K. Tokuda. A hierarchical predictor of synthetic speech naturalness using neural networks, Proc. Interspeech (2016).

\bibitem{qualitynet} S.-W. Fu, Y. Tsao, H.-T. Hwang, and H.-M. Wang, “Quality-Net: An end-to-end non-intrusive speech quality assessment model based on BLSTM,” in Proc. Interspeech, 2018.

\bibitem{mittag} Gabriel Mittag and Sebastian Möller. Deep Learning Based Assessment of Synthetic Speech Naturalness, Interspeech 2020 ISCA (2020).
 
\bibitem{qualityEst} G. Mittag and S. Moller, “Full-reference speech quality estimation with attentional siamese neural networks,” in ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2020, pp. 346–350


\bibitem{nisqacorpus} https://github.com/gabrielmittag/NISQA/wiki/

\bibitem{biasloss} G. Mittag, S. Zadtootaghaj, T. Michael, B. Naderi, and S. Moller, “Bias-aware loss for training image and speech quality prediction models from multiple datasets,” in Accepted at QoMEX 2021.

\bibitem{repogit} https://github.com/asosawelford/Tesis (en progreso)